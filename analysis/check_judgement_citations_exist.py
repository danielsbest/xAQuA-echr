import pandas as pd
import json
from pathlib import Path
from typing import Any
import sys

sys.path.append(str(Path(__file__).resolve().parents[1]))
from src.utils.access_judgement_db import get_database_collection, get_document_by_id
from src.constants import ECHR_CASE_PARAGRAPHS_CSV_PATH

def extract_case_ids(answer: str) -> list[dict[str, str]]:
    """
    Extracts case IDs from a JSON string answer(generated by the model in the QA dataset).
    Returns a list of unique case ID groups, where each group is a dictionary
    mapping language code to case ID.
    """
    try:
        data = json.loads(answer)
    except (json.JSONDecodeError, TypeError):
        return []

    unique_ids_set = set()

    if not isinstance(data, list):
        return []

    for item in data:
        if not isinstance(item, dict) or 'citations' not in item:
            continue
        
        citations = item['citations']
        if not isinstance(citations, list):
            continue

        for citation in citations:
            if not isinstance(citation, dict) or 'multilingual' not in citation:
                continue
            
            multilingual_data = citation['multilingual']
            if not isinstance(multilingual_data, dict):
                continue

            lang_id_map = {
                lang_code: lang_data['id']
                for lang_code, lang_data in multilingual_data.items()
                if isinstance(lang_data, dict) and 'id' in lang_data
            }
            
            if lang_id_map:
                unique_ids_set.add(frozenset(lang_id_map.items()))

    return [dict(t) for t in unique_ids_set]


def analyze_citation_existance(questions_df: pd.DataFrame, existing_case_ids: set[str]) -> dict[str, Any]:
    """
    Analyzes the existence of judgement citations from a DataFrame of questions.
    """
    stats: dict[str, Any] = {
        'total_golden_answers': 0,
        'complete_golden_answers': 0,
        'total_citations_duplicates': 0,
        'total_citations_available': 0,
        'total_citations_not_available': 0,
        'total_citations_no_english': 0,
        'unique_citations_seen': set(),
        'unique_citations_available': 0,
        'unique_citations_not_available': 0,
        'unique_citations_no_english': 0,
    }

    for index, row in questions_df.iterrows():
        answer = row['answer']
        golden_answers = extract_case_ids(answer)
        stats['total_golden_answers'] += 1

        golden_answer_complete_citations = True

        for i, citation_multilang in enumerate(golden_answers):
            stats['total_citations_duplicates'] += 1

            citation_key: Any = None
            if 'eng' in citation_multilang:
                citation_key = citation_multilang['eng']
            elif 'fre' in citation_multilang:
                citation_key = citation_multilang['fre']
            else:
                citation_key = frozenset(citation_multilang.items())
            
            is_new_citation = citation_key not in stats['unique_citations_seen']

            if 'eng' not in citation_multilang.keys():
                print(f"Row {index} Citation {i}: No English version of judgement available")
                golden_answer_complete_citations = False
                stats['total_citations_no_english'] += 1
                if is_new_citation:
                    stats['unique_citations_no_english'] += 1
                    stats['unique_citations_seen'].add(citation_key)
            else:
                eng_case_id = citation_multilang['eng']
                if eng_case_id in existing_case_ids:
                    print(f"Row {index} Citation {i}: Judgement included in judgement database")
                    stats['total_citations_available'] += 1
                    if is_new_citation:
                        stats['unique_citations_available'] += 1
                        stats['unique_citations_seen'].add(citation_key)
                else:
                    print(f"Row {index} Citation {i}: Judgement NOT included in judgement database")
                    golden_answer_complete_citations = False
                    stats['total_citations_not_available'] += 1
                    if is_new_citation:
                        stats['unique_citations_not_available'] += 1
                        stats['unique_citations_seen'].add(citation_key)
        
        if golden_answer_complete_citations:
            stats['complete_golden_answers'] += 1
    
    return stats


def print_statistics(stats: dict[str, Any]):
    """
    Prints the statistics of citation analysis.
    """
    print("\n--- Statistics ---")
    print(f"Total golden answers: {stats['total_golden_answers']}")
    print(f"Complete golden answers (all citations available): {stats['complete_golden_answers']}")
    print(f"Citations in golden answers (with duplicates): {stats['total_citations_duplicates']}")

    total_not_available = stats['total_citations_not_available'] + stats['total_citations_no_english']

    if stats['total_citations_duplicates'] > 0:
        available_perc = (stats['total_citations_available'] / stats['total_citations_duplicates']) * 100
        not_available_perc = (total_not_available / stats['total_citations_duplicates']) * 100
        print(f"Citations available in judgement database: {stats['total_citations_available']} - {available_perc:.2f}%")
        print(f"Citations NOT available in judgement database: {total_not_available} - {not_available_perc:.2f}%")
    else:
        print("Citations available in judgement database: 0 - 0.00%")
        print("Citations NOT available in judgement database: 0 - 0.00%")

    if total_not_available > 0:
        no_eng_perc = (stats['total_citations_no_english'] / total_not_available) * 100
        should_be_available_perc = (stats['total_citations_not_available'] / total_not_available) * 100
        print(f"    of which no English version exists: {stats['total_citations_no_english']} - {no_eng_perc:.2f}%")
        print(f"    of which should be available: {stats['total_citations_not_available']} - {should_be_available_perc:.2f}%")
    else:
        print("    of which no English version exists: 0 - 0.00%")
        print("    of which should be available: 0 - 0.00%")

    # --- Statistics without duplicates ---
    print("\n--- Statistics (without duplicates) ---")
    total_unique_citations = len(stats['unique_citations_seen'])
    print(f"Total unique citations: {total_unique_citations}")

    total_unique_not_available = stats['unique_citations_not_available'] + stats['unique_citations_no_english']

    if total_unique_citations > 0:
        unique_available_perc = (stats['unique_citations_available'] / total_unique_citations) * 100
        unique_not_available_perc = (total_unique_not_available / total_unique_citations) * 100
        print(f"Unique citations available in judgement database: {stats['unique_citations_available']} - {unique_available_perc:.2f}%")
        print(f"Unique citations NOT available in judgement database: {total_unique_not_available} - {unique_not_available_perc:.2f}%")
    else:
        print("Unique citations available in judgement database: 0 - 0.00%")
        print("Unique citations NOT available in judgement database: 0 - 0.00%")

    if total_unique_not_available > 0:
        unique_no_eng_perc = (stats['unique_citations_no_english'] / total_unique_not_available) * 100
        unique_should_be_available_perc = (stats['unique_citations_not_available'] / total_unique_not_available) * 100
        print(f"    of which no English version exists: {stats['unique_citations_no_english']} - {unique_no_eng_perc:.2f}%")
        print(f"    of which should be available: {stats['unique_citations_not_available']} - {unique_should_be_available_perc:.2f}%")
    else:
        print("    of which no English version exists: 0 - 0.00%")
        print("    of which should be available: 0 - 0.00%")


def get_unique_eng_ids(questions_df: pd.DataFrame) -> list[str]:
    """
    Extracts all unique English case IDs from the answers in a DataFrame.
    """
    unique_eng_ids = set()
    for _, row in questions_df.iterrows():
        answer = row['answer']
        golden_answers = extract_case_ids(answer)
        for citation_multilang in golden_answers:
            if 'eng' in citation_multilang:
                unique_eng_ids.add(citation_multilang['eng'])
    return sorted(list(unique_eng_ids))

def get_missing_unique_eng_ids(questions_df: pd.DataFrame, existing_case_ids: set[str]) -> list[str]:
    """
    Extracts unique English case IDs from the answers in a DataFrame that are not present in existing_case_ids.
    """
    all_unique_eng_ids = get_unique_eng_ids(questions_df)
    missing_eng_ids = [eng_id for eng_id in all_unique_eng_ids if eng_id not in existing_case_ids]
    return sorted(list(missing_eng_ids))

def check_ids_in_external_db(missing_ids: list[str]):
    """
    Checks a list of missing case IDs against the chairs MongoDB judgement database.
    Prints statistics on how many were found.
    """
    if not missing_ids:
        print("\n--- External DB Check ---")
        print("No missing IDs to check.")
        return

    print("\n--- Checking Missing IDs in External DB ---")
    try:
        collection = get_database_collection()
    except Exception as e:
        print(f"Could not connect to external DB: {e}")
        return

    found_count = 0
    not_found_count = 0

    for case_id in missing_ids:
        cursor = get_document_by_id(collection, case_id)
        if len(list(cursor)) > 0:
            found_count += 1
        else:
            not_found_count += 1

    print("\n--- External DB Statistics ---")
    total_checked = len(missing_ids)
    if total_checked > 0:
        found_perc = (found_count / total_checked) * 100
        not_found_perc = (not_found_count / total_checked) * 100
        print(f"Total missing IDs checked: {total_checked}")
        print(f"Found in external DB: {found_count} ({found_perc:.2f}%)")
        print(f"Not found in external DB: {not_found_count} ({not_found_perc:.2f}%)")
    else:
        print("Total missing IDs checked: 0")


def main():

    data_dir = Path('data')
    generated_questions_file = data_dir / 'generated_questions_ron_group_full_threshold_0.94_max_length_5000_gemini-2.5-flash-preview-05-20.csv'
    case_paragraphs_file = data_dir / 'echr_case_paragraphs.csv'


    questions_df = pd.read_csv(generated_questions_file)
    paragraphs_df = pd.read_csv(case_paragraphs_file)

    existing_case_ids = set(paragraphs_df['case_id'])

    stats = analyze_citation_existance(questions_df, existing_case_ids)
    print_statistics(stats)

    unique_eng_ids = get_unique_eng_ids(questions_df)
    print("\n--- Unique English Case IDs ---")
    print(f"Found {len(unique_eng_ids)} unique English case IDs.")
    # print(unique_eng_ids)

    missing_eng_ids = get_missing_unique_eng_ids(questions_df, existing_case_ids)
    print("\n--- Missing Unique English Case IDs ---")
    print(f"Found {len(missing_eng_ids)} missing unique English case IDs.")
    print(missing_eng_ids)

    check_ids_in_external_db(missing_eng_ids)


if __name__ == "__main__":
    main()