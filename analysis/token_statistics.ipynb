{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f6d1b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /home/dc/Nextcloud/BachelorsThesis/AQuA_Thesis/Code/echr-qa-benchmark\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "print(f\"Project root: {project_root}\")\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "    \n",
    "from src.column import Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e920b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_dataset_path = \"data/e_ron_rag_qwen3_doc_echr_topic_query_echr_retrieve_gptoss_notranslation.csv\"\n",
    "judgement_paragraphs_path = \"data/echr_case_paragraphs.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pn69ef9uwi",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QA dataset shape: (552, 13)\n",
      "Judgement paragraphs shape: (1070605, 5)\n"
     ]
    }
   ],
   "source": [
    "qa_df = pd.read_csv(os.path.join(project_root, qa_dataset_path))\n",
    "judgement_df = pd.read_csv(os.path.join(project_root, judgement_paragraphs_path))\n",
    "\n",
    "print(f\"QA dataset shape: {qa_df.shape}\")\n",
    "print(f\"Judgement paragraphs shape: {judgement_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1iron13g4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token counting complete!\n"
     ]
    }
   ],
   "source": [
    "encoder = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "def count_tokens(text):\n",
    "    \"\"\"Count tokens in a text string\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return 0\n",
    "    return len(encoder.encode(str(text)))\n",
    "\n",
    "# Calculate token counts for each column\n",
    "qa_df['question_tokens'] = qa_df[Column.QUESTION].apply(count_tokens)\n",
    "qa_df['question_translation_tokens'] = qa_df[Column.QUESTION_TRANSLATION].apply(count_tokens)\n",
    "judgement_df['paragraph_text_tokens'] = judgement_df[Column.ECHR_CASE_PARAGRAPH_TEXT].apply(count_tokens)\n",
    "\n",
    "print(\"Token counting complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "z858t5fipyl",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION token statistics:\n",
      "  Min: 55\n",
      "  Max: 379\n",
      "  Mean: 165.76\n",
      "  Median: 159.0\n",
      "\n",
      "QUESTION_TRANSLATION token statistics:\n",
      "  Min: 29\n",
      "  Max: 225\n",
      "  Mean: 89.76\n",
      "  Median: 86.0\n",
      "\n",
      "ECHR_CASE_PARAGRAPH_TEXT token statistics:\n",
      "  Min: 0\n",
      "  Max: 31272\n",
      "  Mean: 97.99\n",
      "  Median: 71.0\n"
     ]
    }
   ],
   "source": [
    "# statistics for QUESTION column\n",
    "question_stats = {\n",
    "    'min': qa_df['question_tokens'].min(),\n",
    "    'max': qa_df['question_tokens'].max(),\n",
    "    'mean': qa_df['question_tokens'].mean(),\n",
    "    'median': qa_df['question_tokens'].median()\n",
    "}\n",
    "\n",
    "print(\"QUESTION token statistics:\")\n",
    "print(f\"  Min: {question_stats['min']}\")\n",
    "print(f\"  Max: {question_stats['max']}\")\n",
    "print(f\"  Mean: {question_stats['mean']:.2f}\")\n",
    "print(f\"  Median: {question_stats['median']:.1f}\")\n",
    "print()\n",
    "\n",
    "# statistics for QUESTION_TRANSLATION column\n",
    "question_trans_stats = {\n",
    "    'min': qa_df['question_translation_tokens'].min(),\n",
    "    'max': qa_df['question_translation_tokens'].max(),\n",
    "    'mean': qa_df['question_translation_tokens'].mean(),\n",
    "    'median': qa_df['question_translation_tokens'].median()\n",
    "}\n",
    "\n",
    "print(\"QUESTION_TRANSLATION token statistics:\")\n",
    "print(f\"  Min: {question_trans_stats['min']}\")\n",
    "print(f\"  Max: {question_trans_stats['max']}\")\n",
    "print(f\"  Mean: {question_trans_stats['mean']:.2f}\")\n",
    "print(f\"  Median: {question_trans_stats['median']:.1f}\")\n",
    "print()\n",
    "\n",
    "# statistics for ECHR_CASE_PARAGRAPH_TEXT column\n",
    "paragraph_stats = {\n",
    "    'min': judgement_df['paragraph_text_tokens'].min(),\n",
    "    'max': judgement_df['paragraph_text_tokens'].max(),\n",
    "    'mean': judgement_df['paragraph_text_tokens'].mean(),\n",
    "    'median': judgement_df['paragraph_text_tokens'].median()\n",
    "}\n",
    "\n",
    "print(\"ECHR_CASE_PARAGRAPH_TEXT token statistics:\")\n",
    "print(f\"  Min: {paragraph_stats['min']}\")\n",
    "print(f\"  Max: {paragraph_stats['max']}\")\n",
    "print(f\"  Mean: {paragraph_stats['mean']:.2f}\")\n",
    "print(f\"  Median: {paragraph_stats['median']:.1f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
